{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from networkx_viewer import Viewer\n",
    "import matplotlib.colors as mcolors\n",
    "from collections import defaultdict\n",
    "\n",
    "#from model import spcall\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(G, measures, measure_name):\n",
    "  #* https://stackoverflow.com/a/52013202\n",
    "  #* https://aksakalli.github.io/2017/07/17/network-centrality-measures-and-their-visualization.html\n",
    "  #* https://www.datacamp.com/community/tutorials/social-network-analysis-python\n",
    "\n",
    "  #* Create two lists of edges based on their weight.\n",
    "  #* 'elarge' contains edges with weight greater than 5.\n",
    "  #* 'esmall' contains edges with weight less than or equal to 5.\n",
    "  elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] > 5]\n",
    "  esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] <= 5]\n",
    "\n",
    "  #* Generate a spring layout for the graph.\n",
    "  pos = nx.spring_layout(G)\n",
    "\n",
    "  #* Set the size of each node based on its corresponding measure value.\n",
    "  node_size = [v * 1000 for v in measures.values()]\n",
    "\n",
    "  #* Draw the nodes of the graph with their size and color determined by the measure values.\n",
    "  #* The color map 'plt.cm.plasma' is used for coloring the nodes.\n",
    "  nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size, \n",
    "                                  cmap=plt.cm.plasma,\n",
    "                                  node_color=list(measures.values()),\n",
    "                                  nodelist=measures.keys())\n",
    "\n",
    "  #* Set the color normalization of the nodes to be logarithmic.\n",
    "  nodes.set_norm(mcolors.SymLogNorm(linthresh=0.01, linscale=1))\n",
    "  \n",
    "  #* Draw the edges of the graph.\n",
    "  edges = nx.draw_networkx_edges(G, pos)\n",
    "  \n",
    "  #* Draw the 'elarge' and 'esmall' edges with different styles.\n",
    "  #* The 'elarge' edges are drawn with a width of 2.\n",
    "  #* The 'esmall' edges are drawn with a width of 2, transparency of 0.5, blue color, and dashed style.\n",
    "  nx.draw_networkx_edges(G, pos, edgelist=elarge, width=2)\n",
    "  nx.draw_networkx_edges(G, pos, edgelist=esmall, width=2, alpha=0.5, edge_color='blue', style='dashed')\n",
    "\n",
    "  #* Add labels to the nodes with a font size of 10, blue color, and sans-serif font family.\n",
    "  nx.draw_networkx_labels(G, pos, font_size=10, font_color='blue', font_family='sans-serif')\n",
    "  \n",
    "  #* Set the title of the plot, add a color bar, turn off the axis, and display the plot.\n",
    "  plt.title(measure_name)\n",
    "  plt.colorbar(nodes)\n",
    "  plt.axis('off')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_G(G, measures):\n",
    "  #* Define two lists of edges based on their weight.\n",
    "  #* 'elarge' contains edges with weight greater than 5.\n",
    "  #* 'esmall' contains edges with weight less than or equal to 5.\n",
    "  elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] > 5]\n",
    "  esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] <= 5]\n",
    "\n",
    "  #* Generate a spring layout for the graph.\n",
    "  #* This layout treats edges as springs holding nodes close, while treating nodes as repelling objects.\n",
    "  pos = nx.spring_layout(G)\n",
    "  \n",
    "  #* Set the size of each node based on its corresponding measure value.\n",
    "  #* The size is multiplied by 1000 for better visibility.\n",
    "  node_size = [v * 1000 for v in measures.values()]\n",
    "\n",
    "  #* Draw the nodes of the graph with their size and color determined by the measure values.\n",
    "  #* The color map 'plt.cm.plasma' is used for coloring the nodes.\n",
    "  nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size,\n",
    "                                cmap=plt.cm.plasma,\n",
    "                                node_color=list(measures.values()),\n",
    "                                nodelist=measures.keys())\n",
    "\n",
    "  #* Set the color normalization of the nodes to be logarithmic.\n",
    "  #* This can be useful if the measure values vary widely.\n",
    "  nodes.set_norm(mcolors.SymLogNorm(linthresh=0.01, linscale=1))\n",
    "\n",
    "  #* Draw the nodes of the graph again with a fixed size of 50 and a color map of 'plt.cm.plasma'.\n",
    "  nx.draw_networkx_nodes(G, pos, node_size=50, cmap=plt.cm.plasma)\n",
    "\n",
    "  #* Draw the 'elarge' and 'esmall' edges with different styles.\n",
    "  #* The 'elarge' edges are drawn with a width of 2.\n",
    "  #* The 'esmall' edges are drawn with a width of 2, transparency of 0.5, blue color, and dashed style.\n",
    "  nx.draw_networkx_edges(G, pos, edgelist=elarge, width=2)\n",
    "  nx.draw_networkx_edges(G, pos, edgelist=esmall, width=2, alpha=0.5, edge_color='blue', style='dashed')\n",
    "\n",
    "  #* Add labels to the nodes with a font size of 10, black color, and sans-serif font family.\n",
    "  nx.draw_networkx_labels(G ,pos, font_size=10, font_color='black', font_family='sans-serif')\n",
    "\n",
    "  #* Turn off the axis and display the plot.\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Gp(G, measures):\n",
    "  # Set the figure size to make the plot high-definition.\n",
    "  plt.figure(figsize=(50, 50), dpi=300)\n",
    "\n",
    "  #* Define two lists of edges based on their weight.\n",
    "  #* 'elarge' contains edges with weight greater than 5.\n",
    "  #* 'esmall' contains edges with weight less than or equal to 5.\n",
    "  elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] > 5]\n",
    "  esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d['weight'] <= 5]\n",
    "\n",
    "  #* Generate a spring layout for the graph.\n",
    "  #* This layout treats edges as springs holding nodes close, while treating nodes as repelling objects.\n",
    "  pos = nx.spring_layout(G, iterations=13, scale=300, seed=1234)\n",
    "\n",
    "  #* Set the size of each node based on its corresponding measure value.\n",
    "  #* The size is multiplied by 1000 for better visibility.\n",
    "  node_size = [v * 1000 for v in measures.values()]\n",
    "\n",
    "  #* Draw the nodes of the graph with their size and color determined by the measure values.\n",
    "  #* The color map 'plt.cm.plasma' is used for coloring the nodes.\n",
    "  nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size, cmap=plt.cm.plasma, \n",
    "                                  node_color=list(measures.values()),\n",
    "                                  nodelist=measures.keys())\n",
    "\n",
    "  #* Set the color normalization of the nodes to be logarithmic.\n",
    "  #* This can be useful if the measure values vary widely.\n",
    "  nodes.set_norm(mcolors.SymLogNorm(linthresh=0.01, linscale=1))\n",
    "\n",
    "  #* Create a color map based on the node labels.\n",
    "  #* Different labels are mapped to different colors.\n",
    "  color_map = []\n",
    "  for node in G:\n",
    "    if 'fac' in node:\n",
    "        color_map.append('blue')\n",
    "    elif 'stu' in node or '94fbd' in node:\n",
    "        color_map.append('green')\n",
    "    elif 'adm' in node:\n",
    "        color_map.append('yellow')\n",
    "    elif 'sub' in node:\n",
    "        color_map.append('orange')\n",
    "    elif 'isp' in node:\n",
    "        color_map.append('red')\n",
    "    elif 'bis' in node:\n",
    "        color_map.append('purple')\n",
    "    elif 'par' in node:\n",
    "        color_map.append('black')\n",
    "    elif 'sup' in node:\n",
    "        color_map.append('aqua')\n",
    "    elif node in ['grade', 'assignment', 'Bulletin Board', 're-assign', 'enroll', 'register', 'transfer', 'drop']:\n",
    "        color_map.append('white')  # white for the specific nodes\n",
    "    else:\n",
    "        print (node)\n",
    "\n",
    "  #* Draw the nodes of the graph again with a fixed size of 10 and a color map based on the node labels.\n",
    "  nx.draw_networkx_nodes(G, pos, node_size=10, node_color=color_map, cmap=plt.cm.plasma)\n",
    "\n",
    "  #* Draw the 'elarge' and 'esmall' edges with different styles.\n",
    "  #* The 'elarge' edges are drawn with a width of 2 and gray color.\n",
    "  #* The 'esmall' edges are drawn with a width of 2, transparency of 0.5, gray color, and dashed style.\n",
    "  nx.draw_networkx_edges(G, pos, edgelist=elarge, edge_color='gray', width=1)\n",
    "  nx.draw_networkx_edges(G, pos, edgelist=esmall, width=1, alpha=0.5, edge_color='gray', style='dashed')\n",
    "\n",
    "  #* Add labels to the nodes with a font size of 10, gray color, and sans-serif font family.\n",
    "  nx.draw_networkx_labels(G, pos, font_size=3, font_color='black', font_family='sans-serif')\n",
    "\n",
    "  #* Turn off the axis and display the plot.\n",
    "  plt.axis('off')\n",
    "\n",
    "  #* Increase the DPI to 300 for a high-quality plot.\n",
    "  plt.savefig(\"network.png\", dpi=300)\n",
    "  \n",
    "  #* Display the plot \n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_G2(G):\n",
    "  #* Generate a spring layout for the graph.\n",
    "  pos = nx.spring_layout(G)\n",
    "\n",
    "  #* Draw the graph using NetworkX's built-in draw function.\n",
    "  nx.draw_networkx(G)\n",
    "\n",
    "  #* Add labels to the nodes with a font size of 10, gray color, and sans-serif font family.\n",
    "  nx.draw_networkx_labels(G, pos, font_size=10, font_color='gray', font_family='sans-serif')\n",
    "\n",
    "  #* Turn off the axis and display the plot.\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeandrender(filename, centrality):\n",
    "  #* Extract the measure from the centrality dictionary.\n",
    "  cmeasure = centrality[\"measure\"]\n",
    "  \n",
    "  #* Sort the items in the measure dictionary in descending order based on their values.\n",
    "  sorted_x = sorted(cmeasure.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "  #* Check the 'overwrite' flag in the centrality dictionary.\n",
    "  #* If it's True, open the file in write mode, which overwrites the existing content.\n",
    "  #* If it's False, open the file in append mode, which adds to the existing content.\n",
    "  if centrality[\"overwrite\"]:\n",
    "      f = open(filename + centrality[\"prefix\"] + \".txt\", 'w')\n",
    "  else:\n",
    "      f = open(filename + centrality[\"prefix\"] + \".txt\", 'a')\n",
    "  \n",
    "  #* Write the sorted items to the file.\n",
    "  f.write(str(sorted_x))\n",
    "  \n",
    "  #* Close the file.\n",
    "  f.close()\n",
    "\n",
    "  #* Draw the weighted graph with the measure and the name from the centrality dictionary.\n",
    "  draw(G_weighted, centrality[\"measure\"], centrality[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anonymizer for Agent to Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import hashlib\n",
    "# from collections import defaultdict\n",
    "# import pandas as pd\n",
    "# import networkx as nx\n",
    "\n",
    "# def anonymize_id(id):\n",
    "#     prefix = id[0]\n",
    "#     year = id[1:5]\n",
    "#     hash_object = hashlib.sha1(id.encode())\n",
    "#     hex_dig = hash_object.hexdigest()\n",
    "#     if prefix == 'A':\n",
    "#         return 'adm' + hex_dig[:5]\n",
    "#     elif prefix == 'F':\n",
    "#         return 'fac' + hex_dig[:5]\n",
    "#     elif prefix == 'S':\n",
    "#         return 'stu' + hex_dig[:5]\n",
    "#     elif prefix == 'P':\n",
    "#         return 'par' + hex_dig[:5]\n",
    "#     else:\n",
    "#         return 'unk' + hex_dig[:5]\n",
    "\n",
    "# def process_file(filename, is_comment=False):\n",
    "#     with open(filename + \".csv\", 'r') as f:\n",
    "#         reader = csv.reader(f)\n",
    "#         next(reader)\n",
    "\n",
    "#         interactions = defaultdict(int)\n",
    "#         rows = []\n",
    "#         for row in reader:\n",
    "#             initiatorid = anonymize_id(row[0])\n",
    "#             receiverid = anonymize_id(row[2])  # Assuming 'receiverid' is the third column in your CSV file\n",
    "#             # Skip the records that are prefixed with \"unk\"\n",
    "#             if initiatorid.startswith('unk') or receiverid.startswith('unk'):\n",
    "#                 continue\n",
    "#             interactions[(initiatorid, receiverid)] += 1\n",
    "#             if is_comment:  # If it's a comment, transform the commenter and use it as an intermediary node\n",
    "#                 commenter = 'commenter_' + anonymize_id(row[1])\n",
    "#                 rows.append([initiatorid, commenter, receiverid, row[3]])  # Assuming 'ts' is the fourth column in your CSV file\n",
    "#             else:\n",
    "#                 tltype = row[1] if filename != \"reactions\" else row[1]\n",
    "#                 rows.append([initiatorid, tltype, receiverid, row[3]])  # Assuming 'ts' is the fourth column in your CSV file\n",
    "\n",
    "#     # Create a DataFrame from the rows\n",
    "#     df = pd.DataFrame(rows, columns=['initiatorid', 'tltype', 'receiverid', 'ts'])  # Add 'ts' to your DataFrame\n",
    "\n",
    "#     # Convert the 'ts' column to datetime format\n",
    "#     df['ts'] = pd.to_datetime(df['ts'])\n",
    "\n",
    "#     # Define the date range\n",
    "#     start_date = '2021-05-01'\n",
    "#     end_date = '2021-05-31'\n",
    "\n",
    "#     # Filter rows based on the date range\n",
    "#     df = df[(df['ts'] >= start_date) & (df['ts'] <= end_date)]\n",
    "\n",
    "#     # Check if any records prefixed with \"unk\" exist in the DataFrame\n",
    "#     unk_records = df[(df['initiatorid'].str.startswith('unk')) | (df['receiverid'].str.startswith('unk'))]\n",
    "\n",
    "#     if len(unk_records) > 0:\n",
    "#         print(\"Warning: There are records prefixed with 'unk' in the DataFrame.\")\n",
    "#     else:\n",
    "#         print(\"No records prefixed with 'unk' were found in the DataFrame.\")\n",
    "\n",
    "#     # Add a 'weight' column to the DataFrame\n",
    "#     df['weight'] = df.apply(lambda row: interactions[(row['initiatorid'], row['receiverid'])], axis=1)\n",
    "\n",
    "#     return df\n",
    "\n",
    "# # Process each file and concatenate the results into one DataFrame\n",
    "# df_timeline = process_file(\"timeline\")\n",
    "# df_reactions = process_file(\"reactions\")\n",
    "# df_comments = process_file(\"comments\", is_comment=True)\n",
    "\n",
    "# df_all = pd.concat([df_timeline, df_reactions, df_comments])\n",
    "\n",
    "# # Create a new weighted graph.\n",
    "# G_weighted = nx.Graph()\n",
    "\n",
    "# # For each row in the DataFrame, add edges to the graph.\n",
    "# # The nodes are the 'initiatorid', 'tltype', and 'receiverid' columns of the row.\n",
    "# # The weight of the edge is the 'weight' column of the row.\n",
    "# for index, row in df_all.iterrows():\n",
    "#     G_weighted.add_edge(row['initiatorid'], row['tltype'], weight=row['weight'])\n",
    "#     G_weighted.add_edge(row['tltype'], row['receiverid'], weight=row['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Generate a graphml file: \n",
    "#nx.write_graphml_lxml(G_weighted, 'timeline_react_comments_agent_to_tasks_network_may.graphml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the raw CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import hashlib\n",
    "# from collections import defaultdict\n",
    "# import pandas as pd\n",
    "# import networkx as nx\n",
    "\n",
    "# def anonymize_id(id):\n",
    "#     prefix = id[0]\n",
    "#     year = id[1:5]\n",
    "#     hash_object = hashlib.sha1(id.encode())\n",
    "#     hex_dig = hash_object.hexdigest()\n",
    "#     if prefix == 'A':\n",
    "#         return 'adm' + hex_dig[:5]\n",
    "#     elif prefix == 'F':\n",
    "#         return 'fac' + hex_dig[:5]\n",
    "#     elif prefix == 'S':\n",
    "#         return 'stu' + hex_dig[:5]\n",
    "#     elif prefix == 'P':\n",
    "#         return 'par' + hex_dig[:5]\n",
    "#     else:\n",
    "#         return 'unk' + hex_dig[:5]\n",
    "\n",
    "# filename = input(\"Filename:\")\n",
    "# with open(filename + \".csv\", 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     next(reader)\n",
    "\n",
    "#     interactions = defaultdict(int)\n",
    "#     rows = []\n",
    "#     for row in reader:\n",
    "#         initiatorid = anonymize_id(row[0])\n",
    "#         receiverid = anonymize_id(row[1])\n",
    "#         tltype = row[2]\n",
    "#         interactions[(initiatorid, tltype)] += 1\n",
    "#         interactions[(tltype, receiverid)] += 1\n",
    "#         rows.append([initiatorid, tltype, receiverid])\n",
    "\n",
    "# # Create a DataFrame from the rows\n",
    "# df = pd.DataFrame(rows, columns=['initiatorid', 'tltype', 'receiverid'])\n",
    "\n",
    "# # Add a 'weight' column to the DataFrame\n",
    "# df['weight'] = df.apply(lambda row: interactions[(row['initiatorid'], row['tltype'])] + interactions[(row['tltype'], row['receiverid'])], axis=1)\n",
    "\n",
    "# # Now 'df' is a DataFrame that contains your preprocessed data.\n",
    "# initiatorid = df['initiatorid']\n",
    "# tltype = df['tltype']\n",
    "# receiverid = df['receiverid']\n",
    "# weight = df['weight']\n",
    "\n",
    "# # Create a new weighted graph.\n",
    "# G_weighted = nx.Graph()\n",
    "\n",
    "# # For each row in the DataFrame, add edges to the graph.\n",
    "# # The nodes are the 'initiatorid', 'tltype', and 'receiverid' columns of the row.\n",
    "# # The weight of the edge is the 'weight' column of the row.\n",
    "# for index, row in df.iterrows():\n",
    "#     G_weighted.add_edge(row['initiatorid'], row['tltype'], weight=row['weight'])\n",
    "#     G_weighted.add_edge(row['tltype'], row['receiverid'], weight=row['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Plot the graph using the plot_Gp function.\n",
    "#plot_Gp(G_weighted, measures=nx.degree_centrality(G_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Plot the graph using the plot_Gp function.\n",
    "#plot_Gp(G_weighted, measures=nx.betweenness_centrality(G_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Plot the graph using the plot_Gp function.\n",
    "#plot_Gp(G_weighted, measures=nx.eigenvector_centrality(G_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Generate a graphml version of this graph: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Topological Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Print the graph.\n",
    "print(G_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality Measures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Centrality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Calculate the degree centrality of the graph.\n",
    "# degree = nx.degree_centrality(G_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Draw the graph with node sizes proportional to their degree centrality.\n",
    "# draw(G_weighted, nx.degree_centrality(G_weighted), 'Degree Centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Sort the nodes by their degree centrality and print the sorted list.\n",
    "# x = degree\n",
    "# sorted_x = sorted(x.items(), key=lambda kv: kv[1], reverse=True)\n",
    "# for item in sorted_x:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Write the eigenvector centrality to a file and render it.\n",
    "# writeandrender(\n",
    "#     filename, {\n",
    "#         \"measure\": degree,\n",
    "#         \"name\": \"Degree Centrality\",\n",
    "#         \"prefix\": \"degree\",\n",
    "#         \"overwrite\": True\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvector Centrality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Calculate the eigenvector centrality of the graph.\n",
    "# eigenvector = nx.eigenvector_centrality(G_weighted, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Draw the graph with node sizes proportional to their eigenvector centrality.\n",
    "# draw(G_weighted, eigenvector, 'Eigenvector Centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Sort the nodes by their betweenness centrality and print the sorted list.\n",
    "# x = eigenvector\n",
    "# sorted_x = sorted(x.items(), key=lambda kv: kv[1], reverse=True)\n",
    "# for item in sorted_x:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Write the eigenvector centrality to a file.\n",
    "# with open(filename + \"eigen.txt\", 'a') as f:\n",
    "#     f.write(str(eigenvector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Write the eigenvector centrality to a file and render it.\n",
    "# writeandrender(filename,\n",
    "#     {\n",
    "#         \"measure\":eigenvector,\n",
    "#         \"name\": \"Eigenvector Centrality\",\n",
    "#         \"prefix\":\"eigen\",\n",
    "#         \"overwrite\": True\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweenness Centrality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Calculate the betweenness centrality of the graph.\n",
    "# betweenness = nx.betweenness_centrality(G_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Draw the graph with node sizes proportional to their betweenness centrality.\n",
    "# draw(G_weighted, betweenness, 'Betweenness Centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Sort the nodes by their betweenness centrality and print the sorted list.\n",
    "# x = nx.betweenness_centrality(G_weighted)\n",
    "# sorted_x = sorted(x.items(), key=lambda kv: kv[1], reverse=True)\n",
    "# for item in sorted_x:\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Write the betweenness centrality to a file and render it.\n",
    "# writeandrender(\n",
    "#   filename, {\n",
    "#       \"measure\": betweenness,\n",
    "#       \"name\": 'Betweenness Centrality',\n",
    "#       \"prefix\": \"bet\",\n",
    "#       \"overwrite\": True\n",
    "#   }\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
